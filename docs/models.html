
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
  "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">

<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta http-equiv="X-UA-Compatible" content="IE=Edge" />
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <title>models package &#8212; ikkuna 0 documentation</title>
    <link rel="stylesheet" href="_static/alabaster.css" type="text/css" />
    <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
    <script type="text/javascript" id="documentation_options" data-url_root="./" src="_static/documentation_options.js"></script>
    <script type="text/javascript" src="_static/jquery.js"></script>
    <script type="text/javascript" src="_static/underscore.js"></script>
    <script type="text/javascript" src="_static/doctools.js"></script>
    <script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="train package" href="train.html" />
    <link rel="prev" title="main module" href="main.html" />
   
  <link rel="stylesheet" href="_static/custom.css" type="text/css" />
  
  
  <meta name="viewport" content="width=device-width, initial-scale=0.9, maximum-scale=0.9" />

  </head><body>
  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          <div class="body" role="main">
            
  <div class="section" id="models-package">
<h1>models package<a class="headerlink" href="#models-package" title="Permalink to this headline">¶</a></h1>
<div class="section" id="submodules">
<h2>Submodules<a class="headerlink" href="#submodules" title="Permalink to this headline">¶</a></h2>
</div>
<div class="section" id="module-models.alexnet">
<span id="models-alexnet-module"></span><h2>models.alexnet module<a class="headerlink" href="#module-models.alexnet" title="Permalink to this headline">¶</a></h2>
<p>This module defines <a class="reference internal" href="#models.AlexNetMini" title="models.AlexNetMini"><code class="xref py py-class docutils literal notranslate"><span class="pre">models.AlexNetMini</span></code></a>, a reduced version of AlexNet. Adapted from
<code class="xref py py-meth docutils literal notranslate"><span class="pre">torchvision.models.alexnet()</span></code>.</p>
<dl class="class">
<dt id="models.alexnet.AlexNetMini">
<em class="property">class </em><code class="descclassname">models.alexnet.</code><code class="descname">AlexNetMini</code><span class="sig-paren">(</span><em>input_shape</em>, <em>num_classes=1000</em>, <em>exporter=None</em><span class="sig-paren">)</span><a class="headerlink" href="#models.alexnet.AlexNetMini" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>Reduced AlexNet (basically just a few conv layers with relu and
max-pooling) which attempts to adapt to arbitrary input sizes, provided they are large enough to
survive the strides and conv cutoffs.</p>
<dl class="attribute">
<dt id="models.alexnet.AlexNetMini.features">
<code class="descname">features</code><a class="headerlink" href="#models.alexnet.AlexNetMini.features" title="Permalink to this definition">¶</a></dt>
<dd><p><em>torch.nn.Module</em> – Convolutional module, extracting features from the input</p>
</dd></dl>

<dl class="attribute">
<dt id="models.alexnet.AlexNetMini.classifier">
<code class="descname">classifier</code><a class="headerlink" href="#models.alexnet.AlexNetMini.classifier" title="Permalink to this definition">¶</a></dt>
<dd><p><em>torch.nn.Module</em> – Classifier with relu and dropout</p>
</dd></dl>

<dl class="attribute">
<dt id="models.alexnet.AlexNetMini.H_out">
<code class="descname">H_out</code><a class="headerlink" href="#models.alexnet.AlexNetMini.H_out" title="Permalink to this definition">¶</a></dt>
<dd><p><em>int</em> – Output height of the classifier</p>
</dd></dl>

<dl class="attribute">
<dt id="models.alexnet.AlexNetMini.W_out">
<code class="descname">W_out</code><a class="headerlink" href="#models.alexnet.AlexNetMini.W_out" title="Permalink to this definition">¶</a></dt>
<dd><p><em>int</em> – Output width of the classifier</p>
</dd></dl>

<dl class="method">
<dt id="models.alexnet.AlexNetMini.forward">
<code class="descname">forward</code><span class="sig-paren">(</span><em>x</em><span class="sig-paren">)</span><a class="headerlink" href="#models.alexnet.AlexNetMini.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Defines the computation performed at every call.</p>
<p>Should be overridden by all subclasses.</p>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">Although the recipe for forward pass needs to be defined within
this function, one should call the <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</div>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="module-models.densenet">
<span id="models-densenet-module"></span><h2>models.densenet module<a class="headerlink" href="#module-models.densenet" title="Permalink to this headline">¶</a></h2>
<p>From <a class="reference external" href="https://github.com/gpleiss/efficient_densenet_pytorch/blob/master/models/densenet.py">https://github.com/gpleiss/efficient_densenet_pytorch/blob/master/models/densenet.py</a></p>
<dl class="class">
<dt id="models.densenet.DenseNet">
<em class="property">class </em><code class="descclassname">models.densenet.</code><code class="descname">DenseNet</code><span class="sig-paren">(</span><em>input_shape</em>, <em>growth_rate=12</em>, <em>block_config=(16</em>, <em>16</em>, <em>16)</em>, <em>compression=0.5</em>, <em>num_init_features=24</em>, <em>bn_size=4</em>, <em>drop_rate=0</em>, <em>num_classes=10</em>, <em>small_inputs=True</em>, <em>efficient=False</em>, <em>exporter=None</em><span class="sig-paren">)</span><a class="headerlink" href="#models.densenet.DenseNet" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>Densenet-BC model class, based on
<cite>“Densely Connected Convolutional Networks” &lt;https://arxiv.org/pdf/1608.06993.pdf&gt;</cite></p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>growth_rate</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.7)"><em>int</em></a>) – how many filters to add each layer (<code class="docutils literal notranslate"><span class="pre">k</span></code> in paper)</li>
<li><strong>block_config</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#list" title="(in Python v3.7)"><em>list</em></a><em>(</em><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.7)"><em>int</em></a><em>)</em>) – 3 or 4 ints,  how many layers in each pooling block</li>
<li><strong>num_init_features</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.7)"><em>int</em></a>) – the number of filters to learn in the first convolution layer</li>
<li><strong>bn_size</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.7)"><em>int</em></a>) – multiplicative factor for number of bottle neck layers (i.e. <code class="docutils literal notranslate"><span class="pre">bn_size</span></code> * <code class="docutils literal notranslate"><span class="pre">k</span></code>
features in the bottleneck layer)</li>
<li><strong>drop_rate</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.7)"><em>float</em></a>) – dropout rate after each dense layer</li>
<li><strong>num_classes</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.7)"><em>int</em></a>) – number of classification classes</li>
<li><strong>small_inputs</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.7)"><em>bool</em></a>) – set to True if images are <code class="docutils literal notranslate"><span class="pre">32x32</span></code> (e.g. CIFAR). Otherwise assumes images
are larger.</li>
<li><strong>efficient</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.7)"><em>bool</em></a>) – set to <code class="docutils literal notranslate"><span class="pre">True</span></code> to use checkpointing. Much more memory efficient, but slower.</li>
<li><strong>exporter</strong> (<a class="reference internal" href="ikkuna.export.html#ikkuna.export.Exporter" title="ikkuna.export.Exporter"><em>ikkuna.export.Exporter</em></a>) – Optional exporter to use for monitoring</li>
</ul>
</td>
</tr>
</tbody>
</table>
<dl class="method">
<dt id="models.densenet.DenseNet.forward">
<code class="descname">forward</code><span class="sig-paren">(</span><em>x</em><span class="sig-paren">)</span><a class="headerlink" href="#models.densenet.DenseNet.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Defines the computation performed at every call.</p>
<p>Should be overridden by all subclasses.</p>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">Although the recipe for forward pass needs to be defined within
this function, one should call the <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</div>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="models.densenet._DenseBlock">
<em class="property">class </em><code class="descclassname">models.densenet.</code><code class="descname">_DenseBlock</code><span class="sig-paren">(</span><em>num_layers</em>, <em>num_input_features</em>, <em>bn_size</em>, <em>growth_rate</em>, <em>drop_rate</em>, <em>efficient=False</em><span class="sig-paren">)</span><a class="headerlink" href="#models.densenet._DenseBlock" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<dl class="method">
<dt id="models.densenet._DenseBlock.forward">
<code class="descname">forward</code><span class="sig-paren">(</span><em>init_features</em><span class="sig-paren">)</span><a class="headerlink" href="#models.densenet._DenseBlock.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Defines the computation performed at every call.</p>
<p>Should be overridden by all subclasses.</p>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">Although the recipe for forward pass needs to be defined within
this function, one should call the <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</div>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="models.densenet._DenseLayer">
<em class="property">class </em><code class="descclassname">models.densenet.</code><code class="descname">_DenseLayer</code><span class="sig-paren">(</span><em>num_input_features</em>, <em>growth_rate</em>, <em>bn_size</em>, <em>drop_rate</em>, <em>efficient=False</em><span class="sig-paren">)</span><a class="headerlink" href="#models.densenet._DenseLayer" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<dl class="method">
<dt id="models.densenet._DenseLayer.forward">
<code class="descname">forward</code><span class="sig-paren">(</span><em>*prev_features</em><span class="sig-paren">)</span><a class="headerlink" href="#models.densenet._DenseLayer.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Defines the computation performed at every call.</p>
<p>Should be overridden by all subclasses.</p>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">Although the recipe for forward pass needs to be defined within
this function, one should call the <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</div>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="models.densenet._Transition">
<em class="property">class </em><code class="descclassname">models.densenet.</code><code class="descname">_Transition</code><span class="sig-paren">(</span><em>num_input_features</em>, <em>num_output_features</em><span class="sig-paren">)</span><a class="headerlink" href="#models.densenet._Transition" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.container.Sequential</span></code></p>
</dd></dl>

<dl class="function">
<dt id="models.densenet._bn_function_factory">
<code class="descclassname">models.densenet.</code><code class="descname">_bn_function_factory</code><span class="sig-paren">(</span><em>norm</em>, <em>relu</em>, <em>conv</em><span class="sig-paren">)</span><a class="headerlink" href="#models.densenet._bn_function_factory" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</div>
<div class="section" id="module-models">
<span id="module-contents"></span><h2>Module contents<a class="headerlink" href="#module-models" title="Permalink to this headline">¶</a></h2>
<dl class="class">
<dt id="models.AlexNetMini">
<em class="property">class </em><code class="descclassname">models.</code><code class="descname">AlexNetMini</code><span class="sig-paren">(</span><em>input_shape</em>, <em>num_classes=1000</em>, <em>exporter=None</em><span class="sig-paren">)</span><a class="headerlink" href="#models.AlexNetMini" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>Reduced AlexNet (basically just a few conv layers with relu and
max-pooling) which attempts to adapt to arbitrary input sizes, provided they are large enough to
survive the strides and conv cutoffs.</p>
<dl class="attribute">
<dt id="models.AlexNetMini.features">
<code class="descname">features</code><a class="headerlink" href="#models.AlexNetMini.features" title="Permalink to this definition">¶</a></dt>
<dd><p><em>torch.nn.Module</em> – Convolutional module, extracting features from the input</p>
</dd></dl>

<dl class="attribute">
<dt id="models.AlexNetMini.classifier">
<code class="descname">classifier</code><a class="headerlink" href="#models.AlexNetMini.classifier" title="Permalink to this definition">¶</a></dt>
<dd><p><em>torch.nn.Module</em> – Classifier with relu and dropout</p>
</dd></dl>

<dl class="attribute">
<dt id="models.AlexNetMini.H_out">
<code class="descname">H_out</code><a class="headerlink" href="#models.AlexNetMini.H_out" title="Permalink to this definition">¶</a></dt>
<dd><p><em>int</em> – Output height of the classifier</p>
</dd></dl>

<dl class="attribute">
<dt id="models.AlexNetMini.W_out">
<code class="descname">W_out</code><a class="headerlink" href="#models.AlexNetMini.W_out" title="Permalink to this definition">¶</a></dt>
<dd><p><em>int</em> – Output width of the classifier</p>
</dd></dl>

<dl class="method">
<dt id="models.AlexNetMini.forward">
<code class="descname">forward</code><span class="sig-paren">(</span><em>x</em><span class="sig-paren">)</span><a class="headerlink" href="#models.AlexNetMini.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Defines the computation performed at every call.</p>
<p>Should be overridden by all subclasses.</p>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">Although the recipe for forward pass needs to be defined within
this function, one should call the <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</div>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="models.DenseNet">
<em class="property">class </em><code class="descclassname">models.</code><code class="descname">DenseNet</code><span class="sig-paren">(</span><em>input_shape</em>, <em>growth_rate=12</em>, <em>block_config=(16</em>, <em>16</em>, <em>16)</em>, <em>compression=0.5</em>, <em>num_init_features=24</em>, <em>bn_size=4</em>, <em>drop_rate=0</em>, <em>num_classes=10</em>, <em>small_inputs=True</em>, <em>efficient=False</em>, <em>exporter=None</em><span class="sig-paren">)</span><a class="headerlink" href="#models.DenseNet" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>Densenet-BC model class, based on
<cite>“Densely Connected Convolutional Networks” &lt;https://arxiv.org/pdf/1608.06993.pdf&gt;</cite></p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>growth_rate</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.7)"><em>int</em></a>) – how many filters to add each layer (<code class="docutils literal notranslate"><span class="pre">k</span></code> in paper)</li>
<li><strong>block_config</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#list" title="(in Python v3.7)"><em>list</em></a><em>(</em><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.7)"><em>int</em></a><em>)</em>) – 3 or 4 ints,  how many layers in each pooling block</li>
<li><strong>num_init_features</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.7)"><em>int</em></a>) – the number of filters to learn in the first convolution layer</li>
<li><strong>bn_size</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.7)"><em>int</em></a>) – multiplicative factor for number of bottle neck layers (i.e. <code class="docutils literal notranslate"><span class="pre">bn_size</span></code> * <code class="docutils literal notranslate"><span class="pre">k</span></code>
features in the bottleneck layer)</li>
<li><strong>drop_rate</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.7)"><em>float</em></a>) – dropout rate after each dense layer</li>
<li><strong>num_classes</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.7)"><em>int</em></a>) – number of classification classes</li>
<li><strong>small_inputs</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.7)"><em>bool</em></a>) – set to True if images are <code class="docutils literal notranslate"><span class="pre">32x32</span></code> (e.g. CIFAR). Otherwise assumes images
are larger.</li>
<li><strong>efficient</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.7)"><em>bool</em></a>) – set to <code class="docutils literal notranslate"><span class="pre">True</span></code> to use checkpointing. Much more memory efficient, but slower.</li>
<li><strong>exporter</strong> (<a class="reference internal" href="ikkuna.export.html#ikkuna.export.Exporter" title="ikkuna.export.Exporter"><em>ikkuna.export.Exporter</em></a>) – Optional exporter to use for monitoring</li>
</ul>
</td>
</tr>
</tbody>
</table>
<dl class="method">
<dt id="models.DenseNet.forward">
<code class="descname">forward</code><span class="sig-paren">(</span><em>x</em><span class="sig-paren">)</span><a class="headerlink" href="#models.DenseNet.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Defines the computation performed at every call.</p>
<p>Should be overridden by all subclasses.</p>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">Although the recipe for forward pass needs to be defined within
this function, one should call the <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</div>
</dd></dl>

</dd></dl>

</div>
</div>


          </div>
        </div>
      </div>
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">
  <h3><a href="index.html">Table Of Contents</a></h3>
  <ul>
<li><a class="reference internal" href="#">models package</a><ul>
<li><a class="reference internal" href="#submodules">Submodules</a></li>
<li><a class="reference internal" href="#module-models.alexnet">models.alexnet module</a></li>
<li><a class="reference internal" href="#module-models.densenet">models.densenet module</a></li>
<li><a class="reference internal" href="#module-models">Module contents</a></li>
</ul>
</li>
</ul>
<div class="relations">
<h3>Related Topics</h3>
<ul>
  <li><a href="index.html">Documentation overview</a><ul>
  <li><a href="modules.html">ai_ikkuna</a><ul>
      <li>Previous: <a href="main.html" title="previous chapter">main module</a></li>
      <li>Next: <a href="train.html" title="next chapter">train package</a></li>
  </ul></li>
  </ul></li>
</ul>
</div>
  <div role="note" aria-label="source link">
    <h3>This Page</h3>
    <ul class="this-page-menu">
      <li><a href="_sources/models.rst.txt"
            rel="nofollow">Show Source</a></li>
    </ul>
   </div>
<div id="searchbox" style="display: none" role="search">
  <h3>Quick search</h3>
    <div class="searchformwrapper">
    <form class="search" action="search.html" method="get">
      <input type="text" name="q" />
      <input type="submit" value="Go" />
      <input type="hidden" name="check_keywords" value="yes" />
      <input type="hidden" name="area" value="default" />
    </form>
    </div>
</div>
<script type="text/javascript">$('#searchbox').show(0);</script>
        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="footer">
      &copy;2018, Rasmus Diederichsen.
      
      |
      Powered by <a href="http://sphinx-doc.org/">Sphinx 1.7.5</a>
      &amp; <a href="https://github.com/bitprophet/alabaster">Alabaster 0.7.10</a>
      
      |
      <a href="_sources/models.rst.txt"
          rel="nofollow">Page source</a>
    </div>

    

    
  </body>
</html>